{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from excel_matches_livingscores import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load manually tagged samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st1 = pd.read_excel('matches_sample1.xls', encoding = 'utf8')\n",
    "st1 = st1[st1.match.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(clf, X_train, X_test, y_train, y_test):\n",
    "    y_true, y_pred = y_train, clf.predict(X_train)\n",
    "\n",
    "    print(\"Detailed classification report:\\n\")\n",
    "    print(\"Scores on training set.\\n\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(\"Scores on test set.\\n\")\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amdh_full = pd.read_excel('./Amadeus All Properties - FEB 2017 17022017 .xlsx', header=0, index_col='PROPERTY_CODE', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bkgh = load_booking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amdh = load_amadeus_from_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: create these encoders in\n",
    "# http://35.156.49.99:8888/notebooks/idmatching/Automatic%20matching%20with%20feature%20extraction%20and%20candidates%20classifier.ipynb#\n",
    "# otherwise there are some chains missing\n",
    "def create_chain_encoders():\n",
    "    amd_chain = list(norm_text(amdh_full.CHAIN_NAME)) + list(norm_text(amdh.chain))\n",
    "    bkg_chain = norm_text(bkgh.chain)\n",
    "\n",
    "    le_chain = LabelEncoder()\n",
    "    le_chain.fit(amd_chain)\n",
    "    ohe = OneHotEncoder()\n",
    "    ohe.fit(le_chain.transform(amd_chain).reshape(-1,1))\n",
    "\n",
    "    le_chain_bk = LabelEncoder()\n",
    "    le_chain_bk.fit(bkg_chain)\n",
    "    ohe_bk = OneHotEncoder()\n",
    "    ohe_bk.fit(le_chain_bk.transform(bkg_chain).reshape(-1,1))\n",
    "    \n",
    "    with open('chain_encoders.pickle', 'wb') as f:\n",
    "        pickle.dump((le_chain, ohe, le_chain_bk, ohe_bk), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_chain_encoders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_chain_encoders():\n",
    "    with open('chain_encoders.pickle', 'rb') as f:\n",
    "        le_chain, ohe, le_chain_bk, ohe_bk = pickle.load(f)\n",
    "    return le_chain, ohe, le_chain_bk, ohe_bk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process(Xy):\n",
    "    Xy.chain.fillna('', inplace=True)\n",
    "    Xy.chain_bkg.fillna('', inplace=True)\n",
    "    Xy.name.fillna('', inplace=True)\n",
    "    Xy.name_bkg.fillna('', inplace=True)\n",
    "    Xy.chain_included.fillna(False, inplace=True)\n",
    "    Xy.name_included.fillna(False, inplace=True)\n",
    "\n",
    "    Xnum = Xy[[u'dist', u'name_sim', u'name_sim_sw', u'chain_sim', u'chain_sim_sw',\n",
    "           u'name_included', u'chain_included']]\n",
    "\n",
    "    Xcat = Xy[[u'chain', u'chain_bkg']]\n",
    "\n",
    "    le_chain, ohe, le_chain_bk, ohe_bk = load_chain_encoders()\n",
    "    Xchain = le_chain.transform(norm_text(Xy.chain))\n",
    "    Xchain = ohe.transform(Xchain.reshape(-1,1))\n",
    "\n",
    "    Xchain_bkg = le_chain_bk.transform(norm_text(Xy.chain_bkg))\n",
    "    Xchain_bkg = ohe_bk.transform(Xchain_bkg.reshape(-1,1))\n",
    "\n",
    "    X = hstack((Xnum.astype(float), Xchain, Xchain_bkg))\n",
    "    y = Xy.match\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced', 'max_depth': 100, 'n_estimators': 20}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = pre_process(st1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[5,10,20,50,100],\n",
    "    n_estimators=[3, 4, 5, 10, 15, 20],\n",
    "    class_weight=['balanced', 'balanced_subsample', None]\n",
    "    # max_features=[25, 50, 75, 100, 150]\n",
    "    # max_features = [5, 10, 15]\n",
    ")\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(),  \n",
    "    param_grid=params,  # parameters to tune via cross validation\n",
    "    refit=True,  # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,  # number of cores to use for parallelization; -1 for \"all cores\"\n",
    "    scoring='f1',  # what score are we optimizing?\n",
    "    cv=3,  # what type of cross validation to use\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "Scores on training set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00        26\n",
      "        1.0       1.00      1.00      1.00       264\n",
      "\n",
      "avg / total       1.00      1.00      1.00       290\n",
      "\n",
      "Scores on test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.78      0.88        18\n",
      "        1.0       0.96      1.00      0.98       107\n",
      "\n",
      "avg / total       0.97      0.97      0.97       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('rdf_matches.pickle','wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('rdf_matches.pickle','rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # extend classifier to larger sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use this classifier to label more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xy = s[~s.match.notnull()]\n",
    "Xy = Xy.sample(500)\n",
    "X, _ = pre_process(Xy)\n",
    "y = clf.predict(X)\n",
    "Xy.match = y\n",
    "Xy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xy.to_excel('matches_sample2.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check labels manually..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ... then load and fit again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st2 = pd.read_excel('matches_sample2.xls', encoding = 'utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "st = pd.concat([st1,st2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = pre_process(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced_subsample', 'max_depth': 20, 'n_estimators': 50}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "params = dict(\n",
    "    max_depth=[20, 50, 100, 150],\n",
    "    n_estimators=[5, 10, 15, 20, 30, 50],\n",
    "    class_weight=['balanced', 'balanced_subsample', None]\n",
    "    # max_features=[25, 50, 75, 100, 150]\n",
    "    # max_features = [5, 10, 15]\n",
    ")\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(),  \n",
    "    param_grid=params,  # parameters to tune via cross validation\n",
    "    refit=True,  # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,  # number of cores to use for parallelization; -1 for \"all cores\"\n",
    "    scoring='f1',  # what score are we optimizing?\n",
    "    cv=3,  # what type of cross validation to use\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:\n",
      "\n",
      "Scores on training set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      1.00      0.96        69\n",
      "        1.0       1.00      0.99      1.00       617\n",
      "\n",
      "avg / total       0.99      0.99      0.99       686\n",
      "\n",
      "Scores on test set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.84      0.91        25\n",
      "        1.0       0.98      1.00      0.99       204\n",
      "\n",
      "avg / total       0.98      0.98      0.98       229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('rdf_matches.pickle','wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
